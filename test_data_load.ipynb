{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Script for testing loading of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Image Names for Stop and Non-Stop Images\n",
    "stop_image_dir = \"./Data/stop/\"\n",
    "not_stop_image_dir = \"./Data/not_stop/\"\n",
    "stop_image_list =  os.listdir(stop_image_dir)\n",
    "not_stop_image_list =  os.listdir(not_stop_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find distribution of widths and heights\n",
    "n_images = len(stop_image_list) + len(not_stop_image_list)\n",
    "width_distr = np.zeros(n_images)\n",
    "heigth_distr = np.zeros(n_images)\n",
    "\n",
    "#Iterate Over Images\n",
    "for i in range(len(stop_image_list)):\n",
    "    stop_image_name = stop_image_list[i]\n",
    "    temp_image = Image.open(stop_image_dir + stop_image_name)\n",
    "    width_distr[i] = temp_image.width\n",
    "    heigth_distr[i] = temp_image.height\n",
    "\n",
    "for i in range(len(not_stop_image_list)):\n",
    "    not_stop_image_name = not_stop_image_list[i]\n",
    "    temp_image = Image.open(not_stop_image_dir + not_stop_image_name)\n",
    "    width_distr[i+len(stop_image_list)] = temp_image.width\n",
    "    heigth_distr[i+len(stop_image_list)] = temp_image.height\n",
    "\n",
    "#Calculating means as target widths and heights\n",
    "reshape_width = np.round_(np.mean(width_distr)).astype(int)\n",
    "reshape_heigth = np.round_(np.mean(heigth_distr)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Custom DataSet\n",
    "class stopNotStopData(Dataset):\n",
    "    def __init__(self, stop_dir, not_stop_dir, transform=None, targetTransform=None):\n",
    "        self.stop_dir = stop_dir\n",
    "        self.not_stop_dir = not_stop_dir\n",
    "\n",
    "        #Finding Number of Stop and Non-Stop Images\n",
    "        self.stop_image_list =  os.listdir(stop_image_dir)\n",
    "        self.not_stop_image_list =  os.listdir(not_stop_image_dir)\n",
    "        self.n_stop_images = len(self.stop_image_list)\n",
    "        self.n_not_stop_images = len(self.not_stop_image_list)\n",
    "        self.n_images = self.n_not_stop_images + self.n_stop_images\n",
    "\n",
    "        #Creating initial labels for images\n",
    "        self.labels = np.zeros(self.n_images)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.targetTransform = targetTransform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #First find the corresponding image\n",
    "        if idx+1<=self.n_stop_images:\n",
    "            image_name = self.stop_image_list[idx]\n",
    "            image_path = os.path.join(self.stop_dir, image_name)\n",
    "            #Image is a stop image first load it\n",
    "            #image = Image.open(self.stop_dir+str(int(idx+1))+\".JPG\")\n",
    "            image = Image.open(image_path)\n",
    "            #image = np.asarray(image).astype(np.uint8)\n",
    "            label = 0 # 0 is for stop image and 1 is for non-stop image\n",
    "            self.labels[i] = 0 #Set it also in labels array\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.targetTransform:\n",
    "                label = self.targetTransform(label) \n",
    "        else:\n",
    "            idx = idx - self.n_stop_images\n",
    "            image_name = self.not_stop_image_list[idx]\n",
    "            image_path = os.path.join(self.not_stop_dir, image_name)\n",
    "            #image = read_image(self.not_stop_dir+str(int(idx+1))+\".JPG\")\n",
    "            #image = Image.open(self.not_stop_dir+str(int(idx+1))+\".JPG\")\n",
    "            image = Image.open(image_path)\n",
    "            #image = np.asarray(image).astype(np.uint8)\n",
    "            label = 1 # 0 is for stop image and 1 is for non-stop image\n",
    "            self.labels[i] = 1 #Set it also in labels array\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.targetTransform:\n",
    "                label = self.targetTransform(label)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test of Splitting DataSet into train, validation and test\n",
    "#Define Transformation on Image\n",
    "image_transform = transforms.Compose([transforms.Resize(size=(reshape_width, reshape_heigth)), transforms.ToTensor()])\n",
    "#Create DataSet object\n",
    "full_data_set = stopNotStopData(stop_dir=stop_image_dir, not_stop_dir=not_stop_image_dir, transform=image_transform, targetTransform=None)\n",
    "\n",
    "#First Find Number of Elements of each dataset\n",
    "num_elements = np.round_([len(full_data_set)*0.8, len(full_data_set)*0.1, len(full_data_set)*0.1]).astype(int)\n",
    "num_elements[0] = num_elements[0] - (np.sum(num_elements)-len(full_data_set))\n",
    "#Split dataset into three parts\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(full_data_set, num_elements, generator=torch.Generator().manual_seed(75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Test of the training part for basic structure\n",
    "class tevfik_nn(nn.Module):\n",
    "    #Constructor\n",
    "    def __init__(self, out_channel_1 = 16, out_channel_2 = 32):\n",
    "        super(tevfik_nn, self).__init__()\n",
    "        self.out_channel_1 = out_channel_1\n",
    "        self.out_channel_2 = out_channel_2\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.out_channel_1, kernel_size=5, padding=3, stride=2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.out_channel_1, out_channels=self.out_channel_2, kernel_size=3, padding=1, stride=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.linear1 = nn.Linear(out_channel_2*43*31, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        print(x.shape)\n",
    "        #x = self.flatten(x)\n",
    "        x = torch.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "#Device Selection\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(device)\n",
    "\n",
    "#model = tevfik_nn(out_channel_1=8, out_channel_2=16).to(device)\n",
    "#x_test = torch.rand(3, 1300, 946, device=device)\n",
    "#y_yest = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test of writing function to train model\n",
    "# Model Training Function\n",
    "def train_model(model, n_epochs, train_loader, validation_loader, optimizer, criterion, N_test):\n",
    "    cost_list = []\n",
    "    accuracy_list = []\n",
    "    # Loops for each epoch\n",
    "    for epoch in range(n_epochs):\n",
    "        # Keeps track of cost for each epoch\n",
    "        COST=0\n",
    "        # For each batch in train loader\n",
    "        for x, y in train_loader:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n",
    "            optimizer.zero_grad()\n",
    "            # Makes a prediction based on X value\n",
    "            x.to(device)\n",
    "            z = model(x)\n",
    "            # Measures the loss between prediction and acutal Y value\n",
    "            loss = criterion(z, y)\n",
    "            # Calculates the gradient value with respect to each weight and bias\n",
    "            loss.backward()\n",
    "            # Updates the weight and bias according to calculated gradient value\n",
    "            optimizer.step()\n",
    "            # Cumulates loss \n",
    "            COST+=loss.data\n",
    "        \n",
    "        # Saves cost of training data of epoch\n",
    "        cost_list.append(COST)\n",
    "        # Keeps track of correct predictions\n",
    "        correct=0\n",
    "        # Perform a prediction on the validation  data  \n",
    "        for x_test, y_test in validation_loader:\n",
    "            # Makes a prediction\n",
    "            z = model(x_test)\n",
    "            # The class with the max value is the one we are predicting\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            # Checks if the prediction matches the actual value\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        \n",
    "        # Calcualtes accuracy and saves it\n",
    "        accuracy = correct / N_test\n",
    "        accuracy_list.append(accuracy)\n",
    "        print('Epoch' + str(epoch+1) + 'Finished!')\n",
    "    return model, cost_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 1300, 946] at entry 0 and [4, 1300, 946] at entry 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\IBM-CompVision\\test_data_load.ipynb Hücre 9\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m N_test \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(valid_dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#Training the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model, cost_list, accuracy_list \u001b[39m=\u001b[39m train_model(model\u001b[39m=\u001b[39;49mmodel, n_epochs\u001b[39m=\u001b[39;49mn_epochs, train_loader\u001b[39m=\u001b[39;49mtrain_dataloader, validation_loader\u001b[39m=\u001b[39;49mvalid_dataloader, optimizer\u001b[39m=\u001b[39;49moptimizer, criterion\u001b[39m=\u001b[39;49mcriterion, N_test\u001b[39m=\u001b[39;49mN_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), cost_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32md:\\IBM-CompVision\\test_data_load.ipynb Hücre 9\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, n_epochs, train_loader, validation_loader, optimizer, criterion, N_test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m COST\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# For each batch in train loader\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 1300, 946] at entry 0 and [4, 1300, 946] at entry 20"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Test part of the model\n",
    "model = tevfik_nn(out_channel_1=8, out_channel_2=16).to(device)\n",
    "n_epochs = 5\n",
    "\n",
    "# We create a criterion which will measure loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "# Create an optimizer that updates model parameters using the learning rate and gradient\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#Creating DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32 ,shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=len(valid_dataset), shuffle=True)\n",
    "N_test = len(valid_dataset)\n",
    "\n",
    "#Training the model\n",
    "model, cost_list, accuracy_list = train_model(model=model, n_epochs=n_epochs, train_loader=train_dataloader, validation_loader=valid_dataloader, optimizer=optimizer, criterion=criterion, N_test=N_test)\n",
    "\n",
    "plt.plot(range(1,n_epochs+1), cost_list)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1,n_epochs+1), accuracy_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 1300, 946])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 1300, 946] at entry 0 and [4, 1300, 946] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\IBM-CompVision\\test_data_load.ipynb Hücre 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IBM-CompVision/test_data_load.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 1300, 946] at entry 0 and [4, 1300, 946] at entry 1"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test can it be transferrable to dataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32 ,shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=len(valid_dataset), shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test of Convolution and max pooling\n",
    "conv_test = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=3, stride=2)\n",
    "pooling = nn.MaxPool2d(kernel_size=5)\n",
    "\n",
    "test_idx = 5\n",
    "test_x = train_features[test_idx]\n",
    "\n",
    "print(test_x.shape)\n",
    "\n",
    "aft_conv1 = conv_test(test_x)\n",
    "print(type(aft_conv1))\n",
    "print(aft_conv1.shape)\n",
    "\n",
    "aft_pool = pooling(aft_conv1)\n",
    "print(aft_pool.shape)\n",
    "\n",
    "conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
    "aft_conv2 = conv_2(aft_pool)\n",
    "pool_2 = nn.MaxPool2d(kernel_size=3)\n",
    "final = pool_2(aft_conv2)\n",
    "print(final.shape)\n",
    "final = torch.flatten(final)\n",
    "print(final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "\n",
    "idx = randrange(32)\n",
    "\n",
    "#Load the Data\n",
    "data = train_features[idx]\n",
    "[rgb, n_y, n_x] = data.shape\n",
    "\n",
    "image = np.zeros([n_y, n_x ,rgb])\n",
    "for i in range(rgb):\n",
    "    image[:,:,i] = data[i][:][:]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(image)\n",
    "plt.title(str(train_labels[idx]))\n",
    "plt.show()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape_width)\n",
    "print(reshape_heigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
